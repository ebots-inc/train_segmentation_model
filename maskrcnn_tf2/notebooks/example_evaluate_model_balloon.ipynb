{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask-RCNN evaluate model. Balloon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs Memory limit: 2000\n",
      "Physical GPU-devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir('../src')\n",
    "\n",
    "from samples.balloon import balloon\n",
    "from preprocess import preprocess\n",
    "from preprocess import augmentation as aug\n",
    "\n",
    "from model import mask_rcnn_functional\n",
    "import evaluating\n",
    "from common import utils\n",
    "from common import inference_utils\n",
    "from common.inference_utils import process_input\n",
    "from common.config import CONFIG\n",
    "from common.inference_optimize import maskrcnn_to_onnx, modify_onnx_model\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "utils.tf_limit_gpu_memory(tf, 2000)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2021-09-25T16:26:37.569655+03:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.7\n",
      "IPython version      : 7.16.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-65-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n",
      "tensorflow: 2.2.0\n",
      "tqdm      : 4.46.1\n",
      "numpy     : 1.18.5\n",
      "matplotlib: 3.2.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd().replace('src', 'balloon')\n",
    "eval_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.config import CONFIG\n",
    "\n",
    "CONFIG.update(balloon.BALLOON_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found annotation file: via_region_data.json in dataset path: /home/alexander/Documents/py_projects/github/maskrcnn_tf2/balloon/val\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = balloon.BalloonDataset(images_dir=eval_dir,\n",
    "                                     class_key='object',\n",
    "                                     classes_dict=CONFIG['class_dict'],\n",
    "                                     preprocess_transform=preprocess.get_input_preprocess(\n",
    "                                         normalize=CONFIG['normalization']\n",
    "                                     ),\n",
    "                                     json_annotation_key=None,\n",
    "                                     **CONFIG\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataloader DataLoader. Steps per epoch: 13\n"
     ]
    }
   ],
   "source": [
    "eval_dataloader = preprocess.DataLoader(eval_dataset,\n",
    "                                        shuffle=True,\n",
    "                                        cast_output=False,\n",
    "                                        return_original=True,\n",
    "                                         **CONFIG\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../tests/samples/balloon/maskrcnn_mobilenet_246a706912c5d63d633bb39a112cf22c_cp-0045.ckpt'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_path = os.path.join('..', 'tests', 'samples', 'balloon', \n",
    "                            'maskrcnn_mobilenet_246a706912c5d63d633bb39a112cf22c_cp-0045.ckpt'\n",
    "                           )\n",
    "weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] Inference mode\n",
      "WARNING:tensorflow:Layer norm_boxes_anchors is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[MaskRCNN] Backbone architecture: mobilenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/envs/tf_env/lib/python3.7/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] Total params: 24,073,932\n",
      "[MaskRCNN] Trainable params: 23,755,980\n",
      "\n",
      "Weights for inference graph will be transferred from training graph\n",
      "\n",
      "[MaskRCNN] Training mode\n",
      "WARNING:tensorflow:Layer norm_boxes_anchors is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[MaskRCNN] Backbone architecture: mobilenet\n",
      "[MaskRCNN] Total params: 24,073,932\n",
      "[MaskRCNN] Trainable params: 23,755,980\n",
      "MaskRCNN Losses:\n",
      "rpn_class_loss: <layers.losses.RPNClassLoss object at 0x7f54e8137d50>\n",
      "rpn_bbox_loss: <layers.losses.RPNBboxLoss object at 0x7f54cc749750>\n",
      "mrcnn_class_loss: <layers.losses.MRCNNClassLoss object at 0x7f54cc3ab450>\n",
      "mrcnn_bbox_loss: <layers.losses.MRCNNBboxLoss object at 0x7f54cc3ab590>\n",
      "mrcnn_mask_loss: <layers.losses.MRCNNMaskLoss object at 0x7f54cc3abd10>\n",
      "l2_regularizer: <layers.losses.L2RegLoss object at 0x7f54cc671b50>\n",
      "\n",
      "Set weights: conv1_pad\n",
      "Set weights: conv1\n",
      "Set weights: conv1_bn\n",
      "Set weights: conv1_relu\n",
      "Set weights: conv_dw_1\n",
      "Set weights: conv_dw_1_bn\n",
      "Set weights: conv_dw_1_relu\n",
      "Set weights: conv_pw_1\n",
      "Set weights: conv_pw_1_bn\n",
      "Set weights: conv_pw_1_relu\n",
      "Set weights: conv_pad_2\n",
      "Set weights: conv_dw_2\n",
      "Set weights: conv_dw_2_bn\n",
      "Set weights: conv_dw_2_relu\n",
      "Set weights: conv_pw_2\n",
      "Set weights: conv_pw_2_bn\n",
      "Set weights: conv_pw_2_relu\n",
      "Set weights: conv_dw_3\n",
      "Set weights: conv_dw_3_bn\n",
      "Set weights: conv_dw_3_relu\n",
      "Set weights: conv_pw_3\n",
      "Set weights: conv_pw_3_bn\n",
      "Set weights: conv_pw_3_relu\n",
      "Set weights: conv_pad_4\n",
      "Set weights: conv_dw_4\n",
      "Set weights: conv_dw_4_bn\n",
      "Set weights: conv_dw_4_relu\n",
      "Set weights: conv_pw_4\n",
      "Set weights: conv_pw_4_bn\n",
      "Set weights: conv_pw_4_relu\n",
      "Set weights: conv_dw_5\n",
      "Set weights: conv_dw_5_bn\n",
      "Set weights: conv_dw_5_relu\n",
      "Set weights: conv_pw_5\n",
      "Set weights: conv_pw_5_bn\n",
      "Set weights: conv_pw_5_relu\n",
      "Set weights: conv_pad_6\n",
      "Set weights: conv_dw_6\n",
      "Set weights: conv_dw_6_bn\n",
      "Set weights: conv_dw_6_relu\n",
      "Set weights: conv_pw_6\n",
      "Set weights: conv_pw_6_bn\n",
      "Set weights: conv_pw_6_relu\n",
      "Set weights: conv_dw_7\n",
      "Set weights: conv_dw_7_bn\n",
      "Set weights: conv_dw_7_relu\n",
      "Set weights: conv_pw_7\n",
      "Set weights: conv_pw_7_bn\n",
      "Set weights: conv_pw_7_relu\n",
      "Set weights: conv_dw_8\n",
      "Set weights: conv_dw_8_bn\n",
      "Set weights: conv_dw_8_relu\n",
      "Set weights: conv_pw_8\n",
      "Set weights: conv_pw_8_bn\n",
      "Set weights: conv_pw_8_relu\n",
      "Set weights: conv_dw_9\n",
      "Set weights: conv_dw_9_bn\n",
      "Set weights: conv_dw_9_relu\n",
      "Set weights: conv_pw_9\n",
      "Set weights: conv_pw_9_bn\n",
      "Set weights: conv_pw_9_relu\n",
      "Set weights: conv_dw_10\n",
      "Set weights: conv_dw_10_bn\n",
      "Set weights: conv_dw_10_relu\n",
      "Set weights: conv_pw_10\n",
      "Set weights: conv_pw_10_bn\n",
      "Set weights: conv_pw_10_relu\n",
      "Set weights: conv_dw_11\n",
      "Set weights: conv_dw_11_bn\n",
      "Set weights: conv_dw_11_relu\n",
      "Set weights: conv_pw_11\n",
      "Set weights: conv_pw_11_bn\n",
      "Set weights: conv_pw_11_relu\n",
      "Set weights: conv_pad_12\n",
      "Set weights: conv_dw_12\n",
      "Set weights: conv_dw_12_bn\n",
      "Set weights: conv_dw_12_relu\n",
      "Set weights: conv_pw_12\n",
      "Set weights: conv_pw_12_bn\n",
      "Set weights: conv_pw_12_relu\n",
      "Set weights: conv_dw_13\n",
      "Set weights: conv_dw_13_bn\n",
      "Set weights: conv_dw_13_relu\n",
      "Set weights: conv_pw_13\n",
      "Set weights: conv_pw_13_bn\n",
      "Set weights: conv_pw_13_relu\n",
      "Set weights: fpn_c5p5\n",
      "Set weights: fpn_c4p4\n",
      "Set weights: fpn_c3p3\n",
      "Set weights: fpn_c2p2\n",
      "Set weights: fpn_p5\n",
      "Set weights: fpn_p4\n",
      "Set weights: fpn_p3\n",
      "Set weights: fpn_p2\n",
      "Set weights: rpn_conv_shared\n",
      "Set weights: rpn_class_raw\n",
      "Skipped zero-weights layer:  activation\n",
      "Set weights: rpn_bbox_pred\n",
      "Skipped zero-weights layer:  lambda\n",
      "Skipped zero-weights layer:  activation_1\n",
      "Skipped zero-weights layer:  rpn_class_xxx\n",
      "Skipped zero-weights layer:  rpn_bbox_reshape\n",
      "Set weights: mrcnn_mask_conv1\n",
      "Set weights: mrcnn_mask_bn1\n",
      "Set weights: mrcnn_mask_conv2\n",
      "Set weights: mrcnn_mask_bn2\n",
      "Set weights: mrcnn_mask_conv3\n",
      "Set weights: mrcnn_mask_bn3\n",
      "Set weights: mrcnn_mask_conv4\n",
      "Set weights: mrcnn_mask_bn4\n",
      "Set weights: mrcnn_class_conv1\n",
      "Set weights: mrcnn_class_bn1\n",
      "Set weights: mrcnn_class_conv2\n",
      "Set weights: mrcnn_class_bn2\n",
      "Set weights: fpnclf_mrcnn_class_logits\n",
      "Set weights: fpnclf_mrcnn_bbox_fc\n",
      "Set weights: mrcnn_mask_deconv\n",
      "Set weights: mrcnn_mask\n",
      "Model: \"mask_rcnn_inference\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_image (InputLayer)        [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "backbone_mobilenet (Model)      [(None, 256, 256, 64 3228864     input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c5p5 (Conv2D)               (None, 16, 16, 256)  262400      backbone_mobilenet[1][4]         \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p5upsampled (UpSampling2D)  (None, 32, 32, 256)  0           fpn_c5p5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c4p4 (Conv2D)               (None, 32, 32, 256)  131328      backbone_mobilenet[1][3]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2 (TensorFlowOp [(None, 32, 32, 256) 0           fpn_p5upsampled[0][0]            \n",
      "                                                                 fpn_c4p4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p4upsampled (UpSampling2D)  (None, 64, 64, 256)  0           tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c3p3 (Conv2D)               (None, 64, 64, 256)  65792       backbone_mobilenet[1][2]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_1 (TensorFlow [(None, 64, 64, 256) 0           fpn_p4upsampled[0][0]            \n",
      "                                                                 fpn_c3p3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p3upsampled (UpSampling2D)  (None, 128, 128, 256 0           tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpn_c2p2 (Conv2D)               (None, 128, 128, 256 33024       backbone_mobilenet[1][1]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 128, 128, 25 0           fpn_p3upsampled[0][0]            \n",
      "                                                                 fpn_c2p2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p5 (Conv2D)                 (None, 16, 16, 256)  590080      fpn_c5p5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p2 (Conv2D)                 (None, 128, 128, 256 590080      tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p3 (Conv2D)                 (None, 64, 64, 256)  590080      tf_op_layer_AddV2_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p4 (Conv2D)                 (None, 32, 32, 256)  590080      tf_op_layer_AddV2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpn_p6 (MaxPooling2D)           (None, 8, 8, 256)    0           fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rpn_model (Model)               ((None, None, 2), (N 1188864     fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "                                                                 fpn_p6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_rpn_class (Concatenate)  (None, None, 2)      0           rpn_model[1][1]                  \n",
      "                                                                 rpn_model[2][1]                  \n",
      "                                                                 rpn_model[3][1]                  \n",
      "                                                                 rpn_model[4][1]                  \n",
      "                                                                 rpn_model[5][1]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat_rpn_bbox (Concatenate)   (None, None, 4)      0           rpn_model[1][2]                  \n",
      "                                                                 rpn_model[2][2]                  \n",
      "                                                                 rpn_model[3][2]                  \n",
      "                                                                 rpn_model[4][2]                  \n",
      "                                                                 rpn_model[5][2]                  \n",
      "__________________________________________________________________________________________________\n",
      "anchors (AnchorsLayer)          (1, 65472, 4)        261888      input_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "roi (ProposalLayer)             (1, None, 4)         0           concat_rpn_class[0][0]           \n",
      "                                                                 concat_rpn_bbox[0][0]            \n",
      "                                                                 anchors[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_image_meta (InputLayer)   [(None, 14)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "roi_align_classifier (PyramidRO (1, None, 7, 7, 256) 0           roi[0][0]                        \n",
      "                                                                 input_image_meta[0][0]           \n",
      "                                                                 fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_conv1 (TimeDistribu (None, None, 1, 1, 1 12846080    roi_align_classifier[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_bn1 (TimeDistribute (None, None, 1, 1, 1 4096        mrcnn_class_conv1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_relu_act1 (Activation)   (None, None, 1, 1, 1 0           mrcnn_class_bn1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_conv2 (TimeDistribu (None, None, 1, 1, 1 1049600     fpnclf_relu_act1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_class_bn2 (TimeDistribute (None, None, 1, 1, 1 4096        mrcnn_class_conv2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_relu_act2 (Activation)   (None, None, 1, 1, 1 0           mrcnn_class_bn2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_pool_squeeze (Reshape)   (None, 1000, 1024)   0           fpnclf_relu_act2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_class_logits (Time (None, 1000, 2)      2050        fpnclf_pool_squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_bbox_fc (TimeDistr (None, 1000, 8)      8200        fpnclf_pool_squeeze[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_class (TimeDistrib (None, 1000, 2)      0           fpnclf_mrcnn_class_logits[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "fpnclf_mrcnn_bbox_reshape (Resh (None, 1000, 2, 4)   0           fpnclf_mrcnn_bbox_fc[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_detection (DetectionLayer (1, 100, 6)          0           roi[0][0]                        \n",
      "                                                                 fpnclf_mrcnn_class[0][0]         \n",
      "                                                                 fpnclf_mrcnn_bbox_reshape[0][0]  \n",
      "                                                                 input_image_meta[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "detected_boxes_extraction (Dete (1, 100, 4)          0           mrcnn_detection[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "roi_align_mask (PyramidROIAlign (1, 100, 14, 14, 256 0           detected_boxes_extraction[0][0]  \n",
      "                                                                 input_image_meta[0][0]           \n",
      "                                                                 fpn_p2[0][0]                     \n",
      "                                                                 fpn_p3[0][0]                     \n",
      "                                                                 fpn_p4[0][0]                     \n",
      "                                                                 fpn_p5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv1 (TimeDistribut (1, 100, 14, 14, 256 590080      roi_align_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn1 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act1 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv2 (TimeDistribut (1, 100, 14, 14, 256 590080      fpnmask_relu_act1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn2 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act2 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv3 (TimeDistribut (1, 100, 14, 14, 256 590080      fpnmask_relu_act2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn3 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act3 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_conv4 (TimeDistribut (1, 100, 14, 14, 256 590080      fpnmask_relu_act3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_bn4 (TimeDistributed (1, 100, 14, 14, 256 1024        mrcnn_mask_conv4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fpnmask_relu_act4 (Activation)  (1, 100, 14, 14, 256 0           mrcnn_mask_bn4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask_deconv (TimeDistribu (1, 100, 28, 28, 256 262400      fpnmask_relu_act4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "mrcnn_mask (TimeDistributed)    (1, 100, 28, 28, 2)  514         mrcnn_mask_deconv[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 24,073,932\n",
      "Trainable params: 23,755,980\n",
      "Non-trainable params: 317,952\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Loading inference graph and import weights\n",
    "inference_config = CONFIG\n",
    "inference_config.update({'training': False})\n",
    "inference_model = mask_rcnn_functional(config=inference_config)\n",
    "inference_model = inference_utils.load_mrcnn_weights(model=inference_model,\n",
    "                                                     weights_path=weights_path,\n",
    "                                                     verbose=True\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate data on a single batch with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_mrcnn_inference(model, infer_batch, eval_batch):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: tensorflow tf.keras.Model\n",
    "        infer_batch: prepared data for inference\n",
    "        eval_batch:  ground truth data for evaluation\n",
    "\n",
    "    Returns: boxes,\n",
    "             class_ids, \n",
    "             scores, \n",
    "             ull_masks, \n",
    "             eval_gt_boxes, \n",
    "             eval_gt_class_ids, \n",
    "             eval_gt_masks\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract inference inputs from dataloader\n",
    "    batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox, \\\n",
    "    batch_gt_class_ids, batch_gt_boxes, batch_gt_masks = infer_batch\n",
    "\n",
    "    # Extract original inputs from dataloader\n",
    "    eval_gt_image = eval_batch[0][0]\n",
    "    eval_gt_boxes = eval_batch[3][0]\n",
    "    eval_gt_class_ids = eval_batch[2][0]\n",
    "    eval_gt_masks = eval_batch[1][0]\n",
    "    \n",
    "    # Make inference\n",
    "    output = model([batch_images, batch_image_meta])\n",
    "    detections, mrcnn_probs, mrcnn_bbox, mrcnn_mask, rpn_rois, rpn_class, rpn_bbox = output\n",
    "\n",
    "    # Extract bboxes, class_ids, scores and full-size masks\n",
    "    boxes, class_ids, scores, full_masks = \\\n",
    "        utils.reformat_detections(detections=detections[0].numpy(),\n",
    "                                  mrcnn_mask=mrcnn_mask[0].numpy(),\n",
    "                                  original_image_shape=eval_gt_image.shape,\n",
    "                                  image_shape=batch_images[0].shape,\n",
    "                                  window=batch_image_meta[0][7:11]\n",
    "                                  )\n",
    "    return boxes, class_ids, scores, full_masks, eval_gt_boxes, eval_gt_class_ids, eval_gt_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_mrcnn(model, inference_function, eval_dataloader, iou_limits=(0.5, 1), iou_step=0.05):\n",
    "    \"\"\"\n",
    "    Evaluate Mask-RCNN model\n",
    "    Args:\n",
    "        model: tensorflow tf.keras.Model\n",
    "        inference_function:\n",
    "        eval_dataloader:\n",
    "        iou_limits: start and end for IoU in mAP\n",
    "        iou_step:   step for IoU in mAP\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # Evaluate mAP\n",
    "    for eval_iou_threshold in np.arange(iou_limits[0], iou_limits[1], iou_step):\n",
    "\n",
    "        # Metrics lists\n",
    "        ap_list = []\n",
    "        precisions_list = []\n",
    "        recalls_list = []\n",
    "\n",
    "        eval_iterated = iter(eval_dataloader)\n",
    "        pbar = tqdm.tqdm(eval_iterated, total=eval_dataloader.__len__())\n",
    "\n",
    "        for eval_input, _ in pbar:\n",
    "            # Split batch into prepared data for inference and original data for evaluation\n",
    "            infer_batch = eval_input[:-4]\n",
    "            eval_batch = eval_input[-4:]\n",
    "            \n",
    "            try:\n",
    "                boxes, class_ids, scores, full_masks, eval_gt_boxes, eval_gt_class_ids, eval_gt_masks = \\\n",
    "                    inference_function(model=model, infer_batch=infer_batch, eval_batch=eval_batch)\n",
    "\n",
    "                # Get AP, precisions, recalls, overlaps\n",
    "                ap, precisions, recalls, overlaps = \\\n",
    "                    evaluating.compute_ap(gt_boxes=eval_gt_boxes,\n",
    "                                          gt_class_ids=eval_gt_class_ids,\n",
    "                                          gt_masks=eval_gt_masks,\n",
    "                                          pred_boxes=boxes,\n",
    "                                          pred_class_ids=class_ids,\n",
    "                                          pred_scores=scores,\n",
    "                                          pred_masks=full_masks,\n",
    "                                          iou_threshold=eval_iou_threshold\n",
    "                                          )\n",
    "                postfix = ''\n",
    "            except:\n",
    "                postfix = 'Passed an image. AP added as zero.'\n",
    "                ap = 0.0\n",
    "                precisions = 0.0\n",
    "                recalls = 0.0\n",
    "            \n",
    "            ap_list.append(ap)\n",
    "            precisions_list.append(precisions)\n",
    "            recalls_list.append(recalls)\n",
    "\n",
    "            # Update tqdm mAP\n",
    "            pbar.set_description(f\"IoU: {eval_iou_threshold:.2f}. mAP: {np.mean(ap_list):.4f} \")# {postfix}\n",
    "\n",
    "\n",
    "        print(f'mAP={np.mean(ap_list):.4f}, IoU: {eval_iou_threshold:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.50. mAP: 0.3211 : 100%|██████████| 13/13 [00:06<00:00,  2.08it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.3211, IoU: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.55. mAP: 0.3211 : 100%|██████████| 13/13 [00:04<00:00,  2.92it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.3211, IoU: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.60. mAP: 0.3211 : 100%|██████████| 13/13 [00:04<00:00,  2.99it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.3211, IoU: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.65. mAP: 0.3211 : 100%|██████████| 13/13 [00:04<00:00,  2.87it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.3211, IoU: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.70. mAP: 0.3211 : 100%|██████████| 13/13 [00:04<00:00,  3.00it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.3211, IoU: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.75. mAP: 0.3040 : 100%|██████████| 13/13 [00:04<00:00,  2.89it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.3040, IoU: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.80. mAP: 0.2674 : 100%|██████████| 13/13 [00:04<00:00,  3.07it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.2674, IoU: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.85. mAP: 0.1905 : 100%|██████████| 13/13 [00:04<00:00,  2.93it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.1905, IoU: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.90. mAP: 0.1538 : 100%|██████████| 13/13 [00:04<00:00,  2.91it/s]\n",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.1538, IoU: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.95. mAP: 0.0000 : 100%|██████████| 13/13 [00:04<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0000, IoU: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_mrcnn(model=inference_model,\n",
    "               inference_function=tf_mrcnn_inference,\n",
    "               eval_dataloader=eval_dataloader\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate data on a single batch with TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trt_mrcnn_inference(model, infer_batch, eval_batch):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        model: tensorflow tf.keras.Model\n",
    "        infer_batch: prepared data for inference\n",
    "        eval_batch:  ground truth data for evaluation\n",
    "\n",
    "    Returns: boxes,\n",
    "             class_ids, \n",
    "             scores, f\n",
    "             ull_masks, \n",
    "             eval_gt_boxes, \n",
    "             eval_gt_class_ids, \n",
    "             eval_gt_masks\n",
    "\n",
    "    \"\"\"\n",
    "    # Extract inference inputs from dataloader\n",
    "    batch_images, batch_image_meta, batch_rpn_match, batch_rpn_bbox, \\\n",
    "    batch_gt_class_ids, batch_gt_boxes, batch_gt_masks = infer_batch\n",
    "\n",
    "    # Extract original inputs from dataloader\n",
    "    eval_gt_image = eval_batch[0][0]\n",
    "    eval_gt_boxes = eval_batch[3][0]\n",
    "    eval_gt_class_ids = eval_batch[2][0]\n",
    "    eval_gt_masks = eval_batch[1][0]\n",
    "\n",
    "    # Extract trt-variables from a dict for transparency\n",
    "    engine = model['engine']\n",
    "    stream = model['stream']\n",
    "    context = model['context']\n",
    "    device_input = model['device_input']\n",
    "    device_output1 = model['device_output1']\n",
    "    device_output2 = model['device_output2']\n",
    "\n",
    "    host_output1 = model['host_output1']\n",
    "    host_output2 = model['host_output2']\n",
    "    \n",
    "    output_nodes = model['output_nodes']\n",
    "    graph_type = model['graph_type']\n",
    "    \n",
    "    \n",
    "    if graph_type == 'uff':\n",
    "        # Prepare image for uff original graph\n",
    "        input_image, window, scale, padding, crop = utils.resize_image(\n",
    "                eval_gt_image,\n",
    "                min_dim=800,\n",
    "                min_scale=0,\n",
    "                max_dim=1024,\n",
    "                mode='square')\n",
    "        #  Substract channel-mean\n",
    "        input_image = input_image.astype(np.float32) - np.array([123.7, 116.8, 103.9])\n",
    "        \n",
    "        image_shape_reformat = input_image.shape\n",
    "        \n",
    "        # Add batch dimension\n",
    "        batch_images = np.expand_dims(input_image, 0)\n",
    "        # (batch, w, h, 3) -> (batch, 3, w, h)\n",
    "        batch_images = np.moveaxis(batch_images, -1, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        window = batch_image_meta[0][7:11]\n",
    "        image_shape_reformat = batch_images[0].shape\n",
    "\n",
    "    # Make inference\n",
    "    host_input = batch_images.astype(dtype=np.float32, order='C')\n",
    "    cuda.memcpy_htod_async(device_input, host_input, stream)\n",
    "    context.execute_async(bindings=[int(device_input),\n",
    "                                    int(device_output1),\n",
    "                                    int(device_output2),\n",
    "                                    ],\n",
    "                          stream_handle=stream.handle)\n",
    "\n",
    "    cuda.memcpy_dtoh_async(host_output1, device_output1, stream)\n",
    "    cuda.memcpy_dtoh_async(host_output2, device_output2, stream)\n",
    "    stream.synchronize()\n",
    "    \n",
    "    output_shape1 = engine.get_binding_shape(output_nodes[0])\n",
    "    output_shape2 = engine.get_binding_shape(output_nodes[1])\n",
    "    \n",
    "    if graph_type == 'onnx':\n",
    "        trt_mrcnn_detection = host_output1.reshape(output_shape1).astype(dtype=np.float32)\n",
    "        trt_mrcnn_mask = host_output2.reshape(output_shape2).astype(dtype=np.float32)\n",
    "    elif graph_type == 'uff':\n",
    "        # (batch, 100, 6)\n",
    "        trt_mrcnn_detection = host_output1.reshape(\n",
    "            (engine.max_batch_size, *output_shape1)).astype(dtype=np.float32)\n",
    "        # (batch, 100, 2, 28, 28)\n",
    "        trt_mrcnn_mask = host_output2.reshape(\n",
    "            (engine.max_batch_size, *output_shape2)).astype(dtype=np.float32)\n",
    "        # (batch, 100, 2, 28, 28) -> (batch, 100, 28, 28, 2)\n",
    "        trt_mrcnn_mask = np.moveaxis(trt_mrcnn_mask, 2, -1)\n",
    "    else:\n",
    "        raise ValueError(f'Only onnx and uff graph types. Passed: {graph_type}')\n",
    "        \n",
    "\n",
    "    # Extract bboxes, class_ids, scores and full-size masks\n",
    "    trt_boxes, trt_class_ids, trt_scores, trt_full_masks = \\\n",
    "        utils.reformat_detections(detections=trt_mrcnn_detection[0],\n",
    "                                  mrcnn_mask=trt_mrcnn_mask[0],\n",
    "                                  original_image_shape=eval_gt_image.shape,\n",
    "                                  image_shape=image_shape_reformat,\n",
    "                                  window=window\n",
    "                                  )\n",
    "    \n",
    "    return trt_boxes, trt_class_ids, trt_scores, trt_full_masks, eval_gt_boxes, eval_gt_class_ids, eval_gt_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_mrcnn_trt_engine(model_path, output_nodes=['mrcnn_detection', 'mrcnn_mask'], graph_type='onnx'):\n",
    "    \n",
    "    \"\"\"\n",
    "    Load TensorRT engine via pycuda\n",
    "    Args:\n",
    "        model_path: model path to TensorRT-engine\n",
    "        output_nodes: output nodes names\n",
    "        graph_type: onnx or uff\n",
    "\n",
    "    Returns: python dict of attributes for pycuda model inference\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    trt_logger = trt.Logger(trt.Logger.VERBOSE)\n",
    "    trt.init_libnvinfer_plugins(trt_logger, \"\")\n",
    "\n",
    "    with open(model_path, \"rb\") as f, trt.Runtime(trt_logger) as runtime:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    context = engine.create_execution_context()\n",
    "\n",
    "    # Inputs\n",
    "    input_shape = engine.get_binding_shape('input_image')\n",
    "    input_size = trt.volume(input_shape) *\\\n",
    "                 engine.max_batch_size * np.dtype(np.float32).itemsize\n",
    "    device_input = cuda.mem_alloc(input_size)\n",
    "\n",
    "    # Outputs\n",
    "    output_names = list(engine)[1:]\n",
    "\n",
    "    # mrcnn_detection output\n",
    "    output_shape1 = engine.get_binding_shape(output_nodes[0])\n",
    "    host_output1 = cuda.pagelocked_empty(trt.volume(output_shape1) *\n",
    "                                              engine.max_batch_size,\n",
    "                                              dtype=np.float32)\n",
    "    device_output1 = cuda.mem_alloc(host_output1.nbytes)\n",
    "\n",
    "\n",
    "    # mrcnn_mask output\n",
    "    output_shape2 = engine.get_binding_shape(output_nodes[1])\n",
    "    host_output2 = cuda.pagelocked_empty(trt.volume(output_shape2) * engine.max_batch_size,\n",
    "                                              dtype=np.float32)\n",
    "    device_output2 = cuda.mem_alloc(host_output2.nbytes)\n",
    "\n",
    "    # Setting a cuda stream\n",
    "    stream = cuda.Stream()\n",
    "    \n",
    "    return {'engine': engine,\n",
    "            'stream': stream,\n",
    "            'context': context,\n",
    "            'device_input': device_input,\n",
    "            'device_output1': device_output1,\n",
    "            'device_output2':device_output2,\n",
    "            'host_output1': host_output1,\n",
    "            'host_output2': host_output2,\n",
    "            'output_nodes': output_nodes,\n",
    "            'graph_type': graph_type\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.50. mAP: 0.2674 : 100%|██████████| 13/13 [00:03<00:00,  3.94it/s]\n",
      "IoU: 0.55. mAP: 0.3333 :   8%|▊         | 1/13 [00:00<00:01,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.2674, IoU: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.55. mAP: 0.2674 : 100%|██████████| 13/13 [00:02<00:00,  4.73it/s]\n",
      "IoU: 0.60. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.2674, IoU: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.60. mAP: 0.1648 : 100%|██████████| 13/13 [00:02<00:00,  4.50it/s]\n",
      "IoU: 0.65. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  8.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.1648, IoU: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.65. mAP: 0.0879 : 100%|██████████| 13/13 [00:02<00:00,  4.67it/s]\n",
      "IoU: 0.70. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  7.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0879, IoU: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.70. mAP: 0.0769 : 100%|██████████| 13/13 [00:02<00:00,  4.68it/s]\n",
      "IoU: 0.75. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0769, IoU: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.75. mAP: 0.0000 : 100%|██████████| 13/13 [00:02<00:00,  4.55it/s]\n",
      "IoU: 0.80. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0000, IoU: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.80. mAP: 0.0000 : 100%|██████████| 13/13 [00:02<00:00,  4.57it/s]\n",
      "IoU: 0.85. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  7.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0000, IoU: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.85. mAP: 0.0000 : 100%|██████████| 13/13 [00:02<00:00,  4.76it/s]\n",
      "IoU: 0.90. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0000, IoU: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.90. mAP: 0.0000 : 100%|██████████| 13/13 [00:02<00:00,  4.79it/s]\n",
      "IoU: 0.95. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0000, IoU: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.95. mAP: 0.0000 : 100%|██████████| 13/13 [00:02<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0000, IoU: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_mrcnn(model=set_mrcnn_trt_engine(\n",
    "    model_path=f\"\"\"../weights/maskrcnn_{CONFIG['backbone']}_512_512_3_trt_mod_fp32.engine\"\"\"),\n",
    "               inference_function=trt_mrcnn_inference,\n",
    "               eval_dataloader=eval_dataloader\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.50. mAP: 0.2674 : 100%|██████████| 13/13 [00:02<00:00,  5.29it/s]\n",
      "IoU: 0.55. mAP: 0.3333 :   8%|▊         | 1/13 [00:00<00:01,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.2674, IoU: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.55. mAP: 0.2674 : 100%|██████████| 13/13 [00:02<00:00,  5.31it/s]\n",
      "IoU: 0.60. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  9.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.2674, IoU: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.60. mAP: 0.1648 : 100%|██████████| 13/13 [00:02<00:00,  5.34it/s]\n",
      "IoU: 0.65. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.1648, IoU: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.65. mAP: 0.0769 : 100%|██████████| 13/13 [00:02<00:00,  5.25it/s]\n",
      "IoU: 0.70. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0769, IoU: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.70. mAP: 0.0769 : 100%|██████████| 13/13 [00:02<00:00,  5.15it/s]\n",
      "IoU: 0.75. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0769, IoU: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.75. mAP: 0.0769 : 100%|██████████| 13/13 [00:02<00:00,  5.13it/s]\n",
      "IoU: 0.80. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0769, IoU: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.80. mAP: 0.0000 : 100%|██████████| 13/13 [00:02<00:00,  5.17it/s]\n",
      "IoU: 0.85. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0000, IoU: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.85. mAP: 0.0000 : 100%|██████████| 13/13 [00:02<00:00,  5.13it/s]\n",
      "IoU: 0.90. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  9.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0000, IoU: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.90. mAP: 0.0000 : 100%|██████████| 13/13 [00:02<00:00,  5.22it/s]\n",
      "IoU: 0.95. mAP: 0.0000 :   8%|▊         | 1/13 [00:00<00:01,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0000, IoU: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IoU: 0.95. mAP: 0.0000 : 100%|██████████| 13/13 [00:02<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP=0.0000, IoU: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_mrcnn(model=set_mrcnn_trt_engine(\n",
    "    model_path=f\"\"\"../weights/maskrcnn_{CONFIG['backbone']}_512_512_3_trt_mod_fp16.engine\"\"\"),\n",
    "               inference_function=trt_mrcnn_inference,\n",
    "               eval_dataloader=eval_dataloader\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
