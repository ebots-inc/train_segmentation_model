{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaskRCNN training. Common objects in context COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../src')\n",
    "import tensorflow as tf\n",
    "\n",
    "from samples.coco import coco\n",
    "from preprocess import preprocess\n",
    "from preprocess import augmentation as aug\n",
    "from training import train_model\n",
    "from model import mask_rcnn_functional\n",
    "from common.utils import tf_limit_gpu_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2021-09-25T15:51:44.918483+03:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.7.7\n",
      "IPython version      : 7.16.1\n",
      "\n",
      "Compiler    : GCC 7.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.4.0-65-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 12\n",
      "Architecture: 64bit\n",
      "\n",
      "tensorflow: 2.2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs Memory limit: 4500\n",
      "Physical GPU-devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "tf_limit_gpu_memory(tf, 4500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.config import CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_shape': (512, 512, 3),\n",
       " 'img_size': 512,\n",
       " 'backbone': 'mobilenet',\n",
       " 'meta_shape': 93,\n",
       " 'num_classes': 81,\n",
       " 'class_dict': {'background': 0,\n",
       "  'person': 1,\n",
       "  'bicycle': 2,\n",
       "  'car': 3,\n",
       "  'motorcycle': 4,\n",
       "  'airplane': 5,\n",
       "  'bus': 6,\n",
       "  'train': 7,\n",
       "  'truck': 8,\n",
       "  'boat': 9,\n",
       "  'traffic light': 10,\n",
       "  'fire hydrant': 11,\n",
       "  'stop sign': 12,\n",
       "  'parking meter': 13,\n",
       "  'bench': 14,\n",
       "  'bird': 15,\n",
       "  'cat': 16,\n",
       "  'dog': 17,\n",
       "  'horse': 18,\n",
       "  'sheep': 19,\n",
       "  'cow': 20,\n",
       "  'elephant': 21,\n",
       "  'bear': 22,\n",
       "  'zebra': 23,\n",
       "  'giraffe': 24,\n",
       "  'backpack': 25,\n",
       "  'umbrella': 26,\n",
       "  'handbag': 27,\n",
       "  'tie': 28,\n",
       "  'suitcase': 29,\n",
       "  'frisbee': 30,\n",
       "  'skis': 31,\n",
       "  'snowboard': 32,\n",
       "  'sports ball': 33,\n",
       "  'kite': 34,\n",
       "  'baseball bat': 35,\n",
       "  'baseball glove': 36,\n",
       "  'skateboard': 37,\n",
       "  'surfboard': 38,\n",
       "  'tennis racket': 39,\n",
       "  'bottle': 40,\n",
       "  'wine glass': 41,\n",
       "  'cup': 42,\n",
       "  'fork': 43,\n",
       "  'knife': 44,\n",
       "  'spoon': 45,\n",
       "  'bowl': 46,\n",
       "  'banana': 47,\n",
       "  'apple': 48,\n",
       "  'sandwich': 49,\n",
       "  'orange': 50,\n",
       "  'broccoli': 51,\n",
       "  'carrot': 52,\n",
       "  'hot dog': 53,\n",
       "  'pizza': 54,\n",
       "  'donut': 55,\n",
       "  'cake': 56,\n",
       "  'chair': 57,\n",
       "  'couch': 58,\n",
       "  'potted plant': 59,\n",
       "  'bed': 60,\n",
       "  'dining table': 61,\n",
       "  'toilet': 62,\n",
       "  'tv': 63,\n",
       "  'laptop': 64,\n",
       "  'mouse': 65,\n",
       "  'remote': 66,\n",
       "  'keyboard': 67,\n",
       "  'cell phone': 68,\n",
       "  'microwave': 69,\n",
       "  'oven': 70,\n",
       "  'toaster': 71,\n",
       "  'sink': 72,\n",
       "  'refrigerator': 73,\n",
       "  'book': 74,\n",
       "  'clock': 75,\n",
       "  'vase': 76,\n",
       "  'scissors': 77,\n",
       "  'teddy bear': 78,\n",
       "  'hair drier': 79,\n",
       "  'toothbrush': 80},\n",
       " 'normalization': {'mean': [0.485, 0.456, 0.406],\n",
       "  'std': [0.229, 0.224, 0.225]},\n",
       " 'image_min_dim': 300,\n",
       " 'image_min_scale': 0,\n",
       " 'image_max_dim': 512,\n",
       " 'image_resize_mode': 'square',\n",
       " 'use_mini_masks': False,\n",
       " 'mini_mask_shape': (32, 32),\n",
       " 'mask_shape': (28, 28),\n",
       " 'epochs': 100,\n",
       " 'gpu_num': 1,\n",
       " 'batch_size': 1,\n",
       " 'images_per_gpu': 1,\n",
       " 'training': True,\n",
       " 'log_per_steps': 5,\n",
       " 'use_multiprocessing': True,\n",
       " 'workers': 6,\n",
       " 'callback': {'checkpoints_dir': '../logs/scalars',\n",
       "  'reduce_lr_on_plateau': 0.98,\n",
       "  'reduce_lr_on_plateau_patience': 10,\n",
       "  'save_weights_only': True,\n",
       "  'save_best_only': True,\n",
       "  'histogram_freq': 0,\n",
       "  'profile_batch': '1,2'},\n",
       " 'backbone_strides': [4, 8, 16, 32, 64],\n",
       " 'top_down_pyramid_size': 256,\n",
       " 'rpn_anchor_scales': (32, 64, 128, 256, 512),\n",
       " 'rpn_anchor_ratios': [0.5, 1, 2],\n",
       " 'rpn_anchor_stride': 1,\n",
       " 'rpn_train_anchors_per_image': 256,\n",
       " 'max_gt_instances': 100,\n",
       " 'rpn_bbox_std_dev': array([0.1, 0.1, 0.2, 0.2], dtype=float32),\n",
       " 'bbox_std_dev': array([0.1, 0.1, 0.2, 0.2], dtype=float32),\n",
       " 'rpn_nms_threshold': 0.7,\n",
       " 'use_rpn_rois': True,\n",
       " 'random_rois': 0,\n",
       " 'detection_min_confidence': 0.7,\n",
       " 'detection_nms_threshold': 0.3,\n",
       " 'detection_max_instances': 100,\n",
       " 'pre_nms_limit': 6000,\n",
       " 'post_nms_rois_training': 2000,\n",
       " 'post_nms_rois_inference': 1000,\n",
       " 'train_rois_per_image': 200,\n",
       " 'roi_positive_ratio': 0.33,\n",
       " 'pool_size': 7,\n",
       " 'mask_pool_size': 14,\n",
       " 'fpn_cls_fc_layers_size': 1024,\n",
       " 'loss_weights': [1, 1, 1, 1, 1],\n",
       " 'optimizer_kwargs': {'learning_rate': 0.001,\n",
       "  'clipvalue': 5.0,\n",
       "  'name': 'adamax'},\n",
       " 'weight_decay': 0.0002,\n",
       " 'train_bn': False,\n",
       " 'l2_reg_batchnorm': False,\n",
       " 'backbone_init_weights': 'imagenet',\n",
       " 'resnet_leaky_relu': False,\n",
       " 'mask_head_leaky_relu': False,\n",
       " 'cls_head_leaky_relu': False,\n",
       " 'tune_rpn_model_only': False,\n",
       " 'frozen_backbone': False,\n",
       " 'frozen_rpn_model': False,\n",
       " 'frozen_mask_head': False,\n",
       " 'frozen_cls_head': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG.update(coco.COCO_CONFIG)\n",
    "CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] Training mode\n",
      "WARNING:tensorflow:Layer norm_boxes_anchors is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "[MaskRCNN] Backbone architecture: mobilenet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/envs/tf_env/lib/python3.7/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] Total params: 24,499,110\n",
      "[MaskRCNN] Trainable params: 24,181,158\n"
     ]
    }
   ],
   "source": [
    "model = mask_rcnn_functional(config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mobilenet'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG['backbone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None passed to images_dir argument.\n",
      " This means that the dataset class is a child of SegmentationDataset and its behaviour differs from datasets created with VGG Image Annotator.\n",
      " If it is not true, please, check your class arguments carefully.\n",
      "\n",
      "loading annotations into memory...\n",
      "Done (t=10.51s)\n",
      "creating index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/117266 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117266/117266 [00:01<00:00, 70612.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None passed to images_dir argument.\n",
      " This means that the dataset class is a child of SegmentationDataset and its behaviour differs from datasets created with VGG Image Annotator.\n",
      " If it is not true, please, check your class arguments carefully.\n",
      "\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4952/4952 [00:00<00:00, 75245.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.32s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_dir = r'/media/alexander/Samsung_T5/temp/coco2017' \n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "\n",
    "# Initialize training and validation datasets\n",
    "train_dataset = coco.CocoDataset(dataset_dir=base_dir,\n",
    "                                 subset='train',\n",
    "                                 year=2017,\n",
    "                                 auto_download=False,\n",
    "                                 preprocess_transform=preprocess.get_input_preprocess(\n",
    "                                     normalize=CONFIG['normalization']\n",
    "                                 ),\n",
    "                                 augmentation=aug.get_training_augmentation(),\n",
    "                                 **CONFIG\n",
    "                                 )\n",
    "\n",
    "val_dataset = coco.CocoDataset(dataset_dir=base_dir,\n",
    "                               subset='val',\n",
    "                               year=2017,\n",
    "                               auto_download=False,\n",
    "                               preprocess_transform=preprocess.get_input_preprocess(\n",
    "                                   normalize=CONFIG['normalization']\n",
    "                               ),\n",
    "                               **CONFIG\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train DataLoader. Steps per epoch: 117266\n",
      "val DataLoader. Steps per epoch: 4952\n",
      "MaskRCNN Losses:\n",
      "rpn_class_loss: <layers.losses.RPNClassLoss object at 0x7fb984a12110>\n",
      "rpn_bbox_loss: <layers.losses.RPNBboxLoss object at 0x7fbc04a346d0>\n",
      "mrcnn_class_loss: <layers.losses.MRCNNClassLoss object at 0x7fb984a258d0>\n",
      "mrcnn_bbox_loss: <layers.losses.MRCNNBboxLoss object at 0x7fbb9424a090>\n",
      "mrcnn_mask_loss: <layers.losses.MRCNNMaskLoss object at 0x7fbb944ae590>\n",
      "l2_regularizer: <layers.losses.L2RegLoss object at 0x7fbb944a5b50>\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From /home/alexander/anaconda3/envs/tf_env/lib/python3.7/site-packages/tensorflow/python/ops/array_grad.py:644: _EagerTensorBase.cpu (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.identity instead.\n"
     ]
    }
   ],
   "source": [
    "train_model(model, \n",
    "            train_dataset=train_dataset,\n",
    "            val_dataset=val_dataset,\n",
    "            config=CONFIG, \n",
    "            weights_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
